{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Copy of IEEE_MLC_DATASET_LOAD_EXAMPLE.ipynb","provenance":[{"file_id":"https://github.com/IEEE-NITK/AI_for_Wireless_Communication/blob/main/IEEE_MLC_DATASET_LOAD_EXAMPLE%20(1).ipynb","timestamp":1616248253910}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"KyaMGniRAktB","executionInfo":{"status":"ok","timestamp":1616247911334,"user_tz":-330,"elapsed":1274,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["#Import TensorBoard For Logging\n","%load_ext tensorboard "],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"nc8XoMvfiduN","executionInfo":{"status":"ok","timestamp":1616247917530,"user_tz":-330,"elapsed":7202,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["import h5py\n","import os\n","import tensorflow as tf\n","import glob\n","import datetime\n","import gc\n","from keras.callbacks import ModelCheckpoint\n","# import keras\n","import pandas as pd\n","import numpy as np\n","import cv2\n","from scipy.signal import medfilt\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","#import tensorflow_addons as tfa\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","%matplotlib inline"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"enro9AUmi63j"},"source":["# Data Reading / Pre-Processing (Unlabeled Data)\n"]},{"cell_type":"markdown","metadata":{"id":"1skzF3ariq3n"},"source":["## DATA Import Code (Via Drive)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BklvtBZai3mL","executionInfo":{"status":"ok","timestamp":1616247917532,"user_tz":-330,"elapsed":5192,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"5ed2b4f3-8374-49b1-c1e7-bdb9ca81db6e"},"source":["#Mount Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TUlMRPCUq9cI"},"source":["## Function to Read Unlabelled Data"]},{"cell_type":"code","metadata":{"id":"YfVDrYCwidu8","executionInfo":{"status":"ok","timestamp":1616247917533,"user_tz":-330,"elapsed":3699,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["CTW_unlabelled = \"/content/drive/MyDrive/CTW2020/Unzipped/CTW2020_unlabelled_data/\"\n","# path might vary based on how you saved data in your drive"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cU_0wrnMidu_","executionInfo":{"status":"ok","timestamp":1616247917533,"user_tz":-330,"elapsed":2756,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def get_data(data_file):\n","    \n","    f = h5py.File(data_file, 'r')\n","    H_Re = f['H_Re'][:] #shape (sample size, 56, 924, 5)\n","    H_Im = f['H_Im'][:] #shape (sample size, 56, 924, 5)\n","    SNR = f['SNR'][:] #shape (sample size, 56, 5)\n","    f.close()\n","            \n","    return H_Re, H_Im, SNR"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QK0P2T8cui2U","executionInfo":{"status":"ok","timestamp":1616247917534,"user_tz":-330,"elapsed":1937,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"6808b27b-9c9a-4af9-8e58-f00e505e2e53"},"source":["#lists all the files\n","\n","for dirname, _, filenames in os.walk(CTW_unlabelled):\n","    # for filename in filenames:\n","    #     print(os.path.join(dirname, filename))\n","    print(\"Total number of files = {}\".format(len(filenames)))\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Total number of files = 64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ObvHd9YshdbW","executionInfo":{"status":"ok","timestamp":1616247917534,"user_tz":-330,"elapsed":1375,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def preprocessing(H_Re, H_Im):\n","  amp = tf.math.sqrt(tf.math.square(H_Re) + tf.math.square(H_Im))\n","  amp = medfilt(amp, [1, 1, 1, 3])\n","  normalized_amp = tf.keras.utils.normalize(amp)\n","  # avg_amp = tf.reduce_sum(amp, [2, 3])/(amp.shape[2] * amp.shape[3])\n","  # max_amp = tf.reduce_max(amp, 3)\n","  # min_amp = tf.reduce_min(amp, 3)\n","  # if (max_amp - min_amp !=0):\n","  #   normalized_amp = (tf.reshape(amp, [amp.shape[3], amp.shape[0], amp.shape[1], amp.shape[2]]) - min_amp) / (max_amp - min_amp)\n","  #   mormalized_amp = tf.reshape(normalized_amp, [amp.shape[0], amp.shape[1], amp.shape[2], amp.shape[3]])\n","  #   normalized_amp = tf.reshape(normalized_amp, [amp.shape[2], amp.shape[3], amp.shape[0], amp.shape[1]]) * (avg_amp / tf.reduce_max(max_amp))\n","  #   normalized_amp = tf.reshape(normalized_amp, [amp.shape[0], amp.shape[1], amp.shape[2], amp.shape[3]])\n","  # else:\n","  #     normalized_amp = amp\n","  return normalized_amp"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ev2YGZDcngTV","executionInfo":{"status":"ok","timestamp":1616247917905,"user_tz":-330,"elapsed":706,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["## Calling with Start as 1,2,3 will load in distinct sets of 10 (Or mentioned) files \n","\n","def LoadData1():\n","  H_Re=[]\n","  H_Im=[]\n","  SNR=[]\n","  #print(\"Loading Files\")\n","  while True:\n","    for i in range(1):\n","      filename = CTW_unlabelled + \"file_{}.hdf5\".format(i+1)\n","      H_Re, H_Im, SNR= get_data(filename)\n","      i+=1\n","      # YOUR_CODE\n","      # amplitude = preprocessing(H_Re, H_Im)\n","      # filtered_amp = \n","      normalized_amp = preprocessing(H_Re, H_Im)\n","\n","      filtered_snr = medfilt(SNR, [1, 1, 3])\n","      # normalized_snr =  \n","     \n","      yield (normalized_amp,filtered_snr)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yKFTf7d1vMV","executionInfo":{"status":"ok","timestamp":1616247918913,"user_tz":-330,"elapsed":986,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["## Calling with Start as 1,2,3 will load in distinct sets of 10 (Or mentioned) files \n","\n","def LoadData2():\n","  H_Re=[]\n","  H_Im=[]\n","  SNR=[]\n","  #print(\"Loading Files\")\n","  while True:\n","    for i in range(64):\n","      filename = CTW_unlabelled + \"file_{}.hdf5\".format(i+1)\n","      H_Re, H_Im, SNR= get_data(filename)\n","      i+=1\n","       # YOUR_CODE\n","      # amplitude = \n","      # filtered_amp = \n","      normalized_amp = preprocessing(H_Re, H_Im)\n","\n","      filtered_snr = medfilt(SNR, [1, 1, 3])\n","      # normalized_snr =  \n","     \n","      yield (filtered_snr,normalized_amp) #Note the difference in order of variables compared to loaddata1 function\n","\n","     "],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gmGpnRZcqkIz"},"source":["# Define and Train Pretext Task Models"]},{"cell_type":"code","metadata":{"id":"GV2HOCcMqlsh","executionInfo":{"status":"ok","timestamp":1616247920823,"user_tz":-330,"elapsed":1376,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["tf.keras.backend.clear_session()"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7qKkfb-o2St5"},"source":["## Model 1 (Uses H_Re and H_Im)"]},{"cell_type":"code","metadata":{"id":"LENnyXyZMUTT","executionInfo":{"status":"ok","timestamp":1616247922476,"user_tz":-330,"elapsed":1111,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["# Clear any logs from previous runs (Tensorboard)\n","!rm -rf ./logs/"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"by5uMsSaidvG","executionInfo":{"status":"ok","timestamp":1616247923390,"user_tz":-330,"elapsed":1288,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"f4e701f2-4f95-4092-b1a2-e18b516227ce"},"source":["##Tried Leaky Relu -  Errors are too high , so used tanh instead\n","\n","#Base Model is the part we're using for transfer learning\n","#i.e The part that will be transfered\n","\n","#YOUR_CODE\n","#Add CNNs to the basemodel\n","BaseModel1 = tf.keras.Sequential([\n","          tf.keras.layers.Conv2D(128, (3, 3), activation='tanh'),\n","          tf.keras.layers.MaxPooling2D((5,5)),\n","          tf.keras.layers.Dropout(0.5),\n","          tf.keras.layers.Conv2D(64, (3, 3), activation='tanh'),\n","          tf.keras.layers.MaxPooling2D((3, 3)),\n","          tf.keras.layers.Dropout(0.3),\n","          tf.keras.layers.Flatten(),\n","          tf.keras.layers.Dense(462),\n","          tf.keras.layers.Activation('tanh'),\n","          tf.keras.layers.Dense(231)])\n","\n","model1 = tf.keras.Sequential([tf.keras.Input(shape=(56,924,5)),BaseModel1])\n","model1.add(tf.keras.layers.Activation('tanh'))\n","# model1.add(tf.keras.layers.Dense(112))\n","# model1.add(tf.keras.layers.Activation('tanh'))\n","model1.add(tf.keras.layers.Dense(280))\n","model1.add(tf.keras.layers.Reshape((56,5)))\n","print(model1.output_shape)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["(None, 56, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VQCVn_kWpwuX","executionInfo":{"status":"ok","timestamp":1616247925518,"user_tz":-330,"elapsed":1407,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"a9e182a1-3fbf-43e4-bf7a-dc1a03774249","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(BaseModel1.summary())\n","print(model1.summary())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 54, 922, 128)      5888      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 10, 184, 128)      0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 10, 184, 128)      0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 8, 182, 64)        73792     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 2, 60, 64)         0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 2, 60, 64)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 7680)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 462)               3548622   \n","_________________________________________________________________\n","activation (Activation)      (None, 462)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 231)               106953    \n","=================================================================\n","Total params: 3,735,255\n","Trainable params: 3,735,255\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sequential (Sequential)      (None, 231)               3735255   \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 231)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 280)               64960     \n","_________________________________________________________________\n","reshape (Reshape)            (None, 56, 5)             0         \n","=================================================================\n","Total params: 3,800,215\n","Trainable params: 3,800,215\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o49yBIsf7Y6C","executionInfo":{"status":"ok","timestamp":1616247935368,"user_tz":-330,"elapsed":1022,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["model1.compile(optimizer='adam', loss='mse',metrics=['accuracy','mean_absolute_percentage_error'])"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bCT-EPpn7aYU"},"source":["## Train Pretext Model - Part 1 (Using Unlabelled data)"]},{"cell_type":"code","metadata":{"id":"Ozr7zd_OFx4x","executionInfo":{"status":"ok","timestamp":1616247937799,"user_tz":-330,"elapsed":1284,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bi4nqj61ukbU","executionInfo":{"status":"ok","timestamp":1616247937801,"user_tz":-330,"elapsed":683,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["savefilepath1 = \"/content/drive/MyDrive/CTW2020/Checkpoints/PretextModel1/best_model.hdf5\"\n","checkpoint = ModelCheckpoint(savefilepath1, monitor='loss', verbose=1,save_best_only=True, mode='auto')"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7kEoDdBidvJ","outputId":"fc71dd01-d5b0-4bdc-ab1d-18a0a7c5c398","colab":{"base_uri":"https://localhost:8080/"}},"source":["gc.collect()       #Was running out of ram - Added to see if it helps\n","model1.fit(LoadData1(),epochs=5,steps_per_epoch=64 ,verbose = 1,callbacks=[tensorboard_callback,checkpoint])\n","model1.save_weights(savefilepath, overwrite=True, save_format=None, options=None)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qp2tWzRDu25M"},"source":["model1.load_weights(savefilepath1, by_name=False, skip_mismatch=False, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8f72rJHzBw01"},"source":["%tensorboard --logdir logs/fit"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T0cu5yT7JI_L"},"source":["## Model 2 (Uses SNR)"]},{"cell_type":"code","metadata":{"id":"L0EjvU7mMMk7"},"source":["# Clear any logs from previous run (Tensorboard) for the next train sequence (!!!CHECK FOR MORE EFFICIENT WAY)\n","!rm -rf ./logs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"roThhIqbJF7N","outputId":"8df09411-3111-4db2-b27d-43d151e8c424"},"source":["#YOUR_CODE\n","#Add CNNs to the basemodel\n","BaseModel2 = tf.keras.Sequential([tf.keras.layers.Dense(112),tf.keras.layers.Activation('tanh'),tf.keras.layers.Dense(231)])\n","\n","model2 = tf.keras.Sequential([tf.keras.Input(shape=(56,5)),BaseModel2])\n","model2.add(tf.keras.layers.Activation('tanh'))\n","model2.add(tf.keras.layers.Dense(924))\n","model2.add(tf.keras.layers.Activation('tanh'))\n","model2.add(tf.keras.layers.Dense(103488))\n","model2.add(tf.keras.layers.Reshape((2,56,924)))\n","print(model2.output_shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(None, 2, 56, 924)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sqt76UK6LKJQ"},"source":["print(BaseModel2.summary())\n","print(model2.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vdZvck0LNTv"},"source":["model2.compile(optimizer='sgd', loss='mse',metrics=['accuracy','mean_absolute_percentage_error'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ALgCN9_DMg9k"},"source":["## Train Pretext Model - Part 2 (Using Unlabelled data)"]},{"cell_type":"code","metadata":{"id":"HHdzyWTkLdcA"},"source":["savefilepath2 = \"/content/drive/MyDrive/Datasets/CTW2020/Checkpoints/PretextModel2/best_model.hdf5\"\n","checkpoint = ModelCheckpoint(savefilepath2, monitor='loss', verbose=1,save_best_only=True, mode='auto')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HoYE5M8FLhTw"},"source":["gc.collect()       #Was running out of ram - Added to see if it helps\n","model2.fit(LoadData2(),epochs=5,steps_per_epoch=64 ,verbose = 1,callbacks=[tensorboard_callback,checkpoint])\n","model2.save_weights(savefilepath, overwrite=True, save_format=None, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WCX-rZhoLqJ6"},"source":["model1.load_weights(savefilepath2, by_name=False, skip_mismatch=False, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2ZMoMqnLx44"},"source":["%tensorboard --logdir logs/fit"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ReG1LdP4qwxM"},"source":["# Read Labelled data - For downstream Training"]},{"cell_type":"code","metadata":{"id":"9AqvUB3OkMQp"},"source":["# Clear any logs from previous run (Tensorboard) for the next train sequence (!!!CHECK FOR MORE EFFICIENT WAY)\n","!rm -rf ./logs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lSZpQNbSiduy"},"source":["CTW_labelled = \"/content/drive/My Drive/Datasets/CTW2020/Unzipped/CTW2020_labelled_data/\"\n","## path might vary based on how you saved data in your drive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nnmxFT1Gidu2"},"source":["def get_data(data_file):\n","    \n","    f = h5py.File(data_file, 'r')\n","    H_Re = f['H_Re'][:] #shape (sample size, 56, 924, 5)\n","    H_Im = f['H_Im'][:] #shape (sample size, 56, 924, 5)\n","    SNR = f['SNR'][:] #shape (sample size, 56, 5)\n","    Pos = f['Pos'][:] #shape(sample size, 3)\n","    f.close()\n","            \n","    return H_Re, H_Im, SNR, Pos        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nneQ5KE9YV5t","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b1ea117f-f53c-4f11-b2cc-29a101d869b2"},"source":["#lists all the files\n","\n","for dirname, _, filenames in os.walk(CTW_labelled):\n","    # for filename in filenames:\n","    #     print(os.path.join(dirname, filename))\n","    print(\"Total number of files = {}\".format(len(filenames)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total number of files = 9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Hx3UxS1fwBF"},"source":["## Calling with Start as 1,2,3 will load in distinct sets of 10 (Or mentioned) files \n","\n","def LoadData2():\n","  H_Re=[]\n","  H_Im=[]\n","  SNR=[]\n","  #print(\"Loading Files\")\n","  for i in range(64):\n","    filename = CTW_unlabelled + \"file_{}.hdf5\".format(i+1)\n","    H_Re, H_Im, SNR= get_data(filename)\n","    i+=1\n","    \n","    #YOUR_CODE\n","\n","    #Do the data preprocessing as before\n","\n","    yield (SNR , AMP)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6nCmq9q5t_m"},"source":["def LoadData_FinalModel():\n","\n","  H_Re=[]\n","  H_Im=[]\n","  SNR=[]\n","  Pos=[]\n","  \n","  while True:\n","    #print(\"Loading Files\")\n","    for i in range(9):\n","      filename = CTW_labelled + \"file_{}.hdf5\".format(i+1)\n","      H_Re, H_Im, SNR ,Pos= get_data(filename)\n","      i+=1\n","  \n","  #YOUR_CODE\n","\n","    #Do the data preprocessing as before\n","    \n","  \n","      yield ((AMP,SNR),Pos)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ap8a5T1GOa2x"},"source":["# Downstream Model "]},{"cell_type":"code","metadata":{"id":"_PXsuwRaOZo5"},"source":["BaseModel1.trainable = False\n","BaseModel2.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6a_s8iVBOkOz"},"source":["Input1 = tf.keras.Input(shape=(2,56,924))\n","Input2 = tf.keras.Input(shape=(56))\n","\n","Output = tf.keras.layers.concatenate([BaseModel1(Input1), BaseModel2(Input2)], axis = 1)\n","\n","Output = tf.keras.layers.Activation('tanh')(Output)\n","Output = tf.keras.layers.Dense(100)(Output)\n","Output = tf.keras.layers.Activation('tanh')(Output)\n","Output = tf.keras.layers.Dense(56)(Output)\n","Output = tf.keras.layers.Activation('tanh')(Output)\n","Output = tf.keras.layers.Dense(3)(Output)\n","\n","FinalModel = tf.keras.Model(inputs=[Input1,Input2], outputs=Output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QYL_VlimWe1V"},"source":["FinalModel.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2icFdjG6Xr_I"},"source":["FinalModel.compile(optimizer='sgd', loss='mse',metrics=['accuracy','mean_absolute_percentage_error'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqubRueb7UPE"},"source":["savefilepath_FinalModel = \"/content/drive/My Drive/Datasets/CTW2020/Checkpoints/DownstreamModel/best_model.hdf5\"\n","checkpoint = ModelCheckpoint(savefilepath_FinalModel, monitor='loss', verbose=1,save_best_only=True, mode='auto')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpFe1bag7Dhv"},"source":["gc.collect()       #Was running out of ram - Added to see if it helps\n","FinalModel.fit(LoadData_FinalModel(),steps_per_epoch=9 ,epochs=5 ,verbose = 1,callbacks=[tensorboard_callback,checkpoint])\n","FinalModel.save_weights(savefilepath_FinalModel, overwrite=True, save_format=None, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rg8MDk348NeX"},"source":["FinalModel.load_weights(savefilepath, by_name=False, skip_mismatch=False, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sd8X9pluZ385"},"source":["%tensorboard --logdir logs/fit"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0t2W8tJnkJGJ"},"source":["##Code for Tuning Part"]},{"cell_type":"code","metadata":{"id":"qbCkUIQxkIG-"},"source":["# Clear any logs from previous run (Tensorboard) for the next train sequence (!!!CHECK FOR MORE EFFICIENT WAY)\n","# !rm -rf ./logs/\n","\n","#Make trainable\n","BaseModel1.trainable = True\n","BaseModel2.trainable = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZ__FeJQkNkX"},"source":["FinalModel.compile(optimizer='sgd', loss='mse',metrics=['accuracy','mean_absolute_percentage_error'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SXA9dClqkSQ7"},"source":["gc.collect()       #Was running out of ram - Added to see if it helps\n","FinalModel.fit(LoadData_FinalModel(),epochs=5 , steps_per_epoch=9 ,verbose = 1,callbacks=[tensorboard_callback,checkpoint])\n","FinalModel.save_weights(savefilepath_FinalModel, overwrite=True, save_format=None, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v1iio8-dTmL_"},"source":["FinalModel.load_weights(savefilepath_FinalModel, by_name=False, skip_mismatch=False, options=None)"],"execution_count":null,"outputs":[]}]}